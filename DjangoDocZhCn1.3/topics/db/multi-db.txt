==================
使用多个数据库
==================

.. versionadded:: 1.2

大多数其他文档都假设使用单一数据库，本文主要讨论如何在 Django 中使用多个数据库。
使用多个数据库，要增加一些步骤。

定义你的数据库
=======================

使用多数据库的第一步是通过 :setting:`DATABASES` 设置要使用的数据库服务。这个
设置用于映射数据库别名和特定的联结设置字典，这是 Django 定义数据库一贯的手法。
字典内部的设置参见 :setting:`DATABASES` 文档。

数据库可以使用任何别名，但是 ``default`` 有特殊意义。当没有选择其他数据库时，
Django 总是使用别名为 ``default`` 的数据库。因此，如果你没有定义一个名为
``default`` 的数据库时，你应当小心了，在使用数据库前要指定你想用的数据库。

以下是一个定义两个数据库的 ``settings.py`` 代码片断。定义了一个缺省的
PostgreSQL 数据库和一个名为 ``users`` 的 MySQL 数据库：

.. code-block:: python

    DATABASES = {
        'default': {
            'NAME': 'app_data',
            'ENGINE': 'django.db.backends.postgresql_psycopg2',
            'USER': 'postgres_user',
            'PASSWORD': 's3krit'
        },
        'users': {
            'NAME': 'user_data',
            'ENGINE': 'django.db.backends.mysql',
            'USER': 'mysql_user',
            'PASSWORD': 'priv4te'
        }
    }

如果你尝试访问 :setting:`DATABASES` 设置中没有定义的数据库， Django 会抛出一个
``django.db.utils.ConnectionDoesNotExist`` 异常。

同步你的数据库
============================

:djadmin:`syncdb` 管理命令一次只操作一个数据库。缺省情况下，它操作 ``default``
数据库。但是加上 :djadminopt:`--database` 参数，你可以让 syncdb 同步不同的
数据库。所以要同步我们例子中的所有数据库的所有模型可以使用如下命令::

    $ ./manage.py syncdb
    $ ./manage.py syncdb --database=users

如果你不是同步所有的程序到同一个数据库中，你可定义一个
:ref:`数据库路由<topics-db-multi-db-routing>` 来为指定的模型实施特定的控制
策略。

如果你要精细地控制同步，那么还有一种方式是修改 :djadmin:`sqlall` 的输出，手工在
数据库中执行命令，命令如下::

    $ ./manage.py sqlall sales | ./manage.py dbshell

使用其他管理命令
-------------------------------

其他操作数据库的 ``django-admin.py`` 命令与 :djadmin:`syncdb` 类似，他们一次只
操作一个数据库，使用 :djadminopt:`--database` 来控制使用哪个数据库。

.. _topics-db-multi-db-routing:

自动数据库路由
==========================

使用多数据库最简单的方法是设置一个数据库路由方案。缺省的路由方案确保对象
“紧贴”其原本的数据库（例如：一个对象从哪个数据库取得，就保存回哪个数据库）。
缺省的路由方案还确保如果一个数据库没有指定，所有的查询都会作用于 ``缺省`` 数据
库。

你不必为启动缺省路由方案作任何事，因为它是“开箱即用”的。但是，如果你要执行
一些更有趣的数据库分配行为的话，你可以定义并安装你自己的数据库路由。

数据库路由
----------------

一个数据库路由是一个类，这个类最多有四个方法：

.. method:: db_for_read(model, **hints)

    建议 ``model`` 对象写操作时使用的数据库。

    如果一个数据库操作可以提供对选择数据库有用的附加信息，那么可以通过
    ``hints`` 字典提供。详见 :ref:`下文 <topics-db-multi-db-hints>` 。

    如果没有建议则返回 None 。

.. method:: db_for_write(model, **hints)

    建议 ``model`` 对象读操作时使用的数据库。

    如果一个数据库操作可以提供对选择数据库有用的附加信息，那么可以通过
    ``hints`` 字典提供。详见 :ref:`下文 <topics-db-multi-db-hints>` 。

    如果没有建议则返回 None 。

.. method:: allow_relation(obj1, obj2, **hints)

    当 obj1 和 obj2 之间允许有关系时返回 True ，不允许时返回 False ，或者没有
    意见时返回 None 。这是一个纯粹的验证操作，用于外键和多对多操作中，两个对象
    的关系是否被允许。

.. method:: allow_syncdb(db, model)

    决定 ``model`` 是否可以和 ``db`` 为别名的数据库同步。如果可以返回 True ，
    如果不可以返回 False ，或者没有意见时返回 None 。这个方法用于决定一个给定
    数据库的模型是否可用。

一个路由不必提供 *所有* 这些方法，可以省略其中一个或多个。如果其中一个方法被
省略了，那么 Django 会在执行相关检查时跳过相应路由。

.. _topics-db-multi-db-hints:

提示参数
~~~~~~~~

数据库路由接收的“提示”参数可用于决定哪个数据库应当接收一个给定的请求。

目前，唯一可以提供的提示参数是 ``实例`` ，即一个与读写操作相关的对象的实例。
可以是一个已保存的对象的实例，也可以是一个多对多关系中添加的实例。在某些情况下，
也可能没有对象的实例可以提供。路由会检查提示实例是否存在，并相应地决定是否改变
路由行为。

使用路由
--------

数据库路由使用 :setting:`DATABASE_ROUTERS` 设置来安装。这个设置定义一个类名称
列表，每个类定义一个用于主路由 (``django.db.router``) 的路由。

主路由用于 Django 分配数据库操作。当一个查询想要知道使用哪个数据库时，会提供
一个模型和一个提示（如果有的话），并调用主路由。 Django 就会按次序尝试每个路由，
直到找到合适的路由建议。如果找不到路由建议就会尝试实例提示的当前的
``_state.db`` 。如果没有提供路由提示，或者实例没有当前数据库状态，那么主路由会
分配 ``缺省`` 数据库。

一个例子
--------

.. admonition:: 仅用于示例目的！

    这个例子仅用于展示路由如何改变数据库的使用。本例有意忽略了一些复杂的东西以
    便于更好的展示路由是如何工作的。

    如果任何一个 ``myapp`` 中的模型包含与 ``另一个`` 数据库中模型的关系时，本例
    是无效的。 :ref:`跨数据库关系 <no_cross_database_relations>` 一节中介绍了
    Django 引用完整性问题。

    The master/slave configuration described is also flawed -- it
    doesn't provide any solution for handling replication lag (i.e.,
    query inconsistencies introduced because of the time taken for a
    write to propagate to the slaves). It also doesn't consider the
    interaction of transactions with the database utilization strategy.

So - what does this mean in practice? Say you want ``myapp`` to
exist on the ``other`` database, and you want all other models in a
master/slave relationship between the databases ``master``, ``slave1`` and
``slave2``. To implement this, you would need 2 routers::

    class MyAppRouter(object):
        """A router to control all database operations on models in
        the myapp application"""

        def db_for_read(self, model, **hints):
            "Point all operations on myapp models to 'other'"
            if model._meta.app_label == 'myapp':
                return 'other'
            return None

        def db_for_write(self, model, **hints):
            "Point all operations on myapp models to 'other'"
            if model._meta.app_label == 'myapp':
                return 'other'
            return None

        def allow_relation(self, obj1, obj2, **hints):
            "Allow any relation if a model in myapp is involved"
            if obj1._meta.app_label == 'myapp' or obj2._meta.app_label == 'myapp':
                return True
            return None

        def allow_syncdb(self, db, model):
            "Make sure the myapp app only appears on the 'other' db"
            if db == 'other':
                return model._meta.app_label == 'myapp'
            elif model._meta.app_label == 'myapp':
                return False
            return None

    class MasterSlaveRouter(object):
        """A router that sets up a simple master/slave configuration"""

        def db_for_read(self, model, **hints):
            "Point all read operations to a random slave"
            return random.choice(['slave1','slave2'])

        def db_for_write(self, model, **hints):
            "Point all write operations to the master"
            return 'master'

        def allow_relation(self, obj1, obj2, **hints):
            "Allow any relation between two objects in the db pool"
            db_list = ('master','slave1','slave2')
            if obj1._state.db in db_list and obj2._state.db in db_list:
                return True
            return None

        def allow_syncdb(self, db, model):
            "Explicitly put all models on all databases."
            return True

Then, in your settings file, add the following (substituting ``path.to.`` with
the actual python path to the module where you define the routers)::

    DATABASE_ROUTERS = ['path.to.MyAppRouter', 'path.to.MasterSlaveRouter']

The order in which routers are processed is significant. Routers will
be queried in the order the are listed in the
:setting:`DATABASE_ROUTERS` setting . In this example, the
``MyAppRouter`` is processed before the ``MasterSlaveRouter``, and as a
result, decisions concerning the models in ``myapp`` are processed
before any other decision is made. If the :setting:`DATABASE_ROUTERS`
setting listed the two routers in the other order,
``MasterSlaveRouter.allow_syncdb()`` would be processed first. The
catch-all nature of the MasterSlaveRouter implementation would mean
that all models would be available on all databases.

With this setup installed, lets run some Django code::

    >>> # This retrieval will be performed on the 'credentials' database
    >>> fred = User.objects.get(username='fred')
    >>> fred.first_name = 'Frederick'

    >>> # This save will also be directed to 'credentials'
    >>> fred.save()

    >>> # These retrieval will be randomly allocated to a slave database
    >>> dna = Person.objects.get(name='Douglas Adams')

    >>> # A new object has no database allocation when created
    >>> mh = Book(title='Mostly Harmless')

    >>> # This assignment will consult the router, and set mh onto
    >>> # the same database as the author object
    >>> mh.author = dna

    >>> # This save will force the 'mh' instance onto the master database...
    >>> mh.save()

    >>> # ... but if we re-retrieve the object, it will come back on a slave
    >>> mh = Book.objects.get(title='Mostly Harmless')


Manually selecting a database
=============================

Django also provides an API that allows you to maintain complete control
over database usage in your code. A manually specified database allocation
will take priority over a database allocated by a router.

Manually selecting a database for a ``QuerySet``
------------------------------------------------

You can select the database for a ``QuerySet`` at any point in the
``QuerySet`` "chain." Just call ``using()`` on the ``QuerySet`` to get
another ``QuerySet`` that uses the specified database.

``using()`` takes a single argument: the alias of the database on
which you want to run the query. For example::

    >>> # This will run on the 'default' database.
    >>> Author.objects.all()

    >>> # So will this.
    >>> Author.objects.using('default').all()

    >>> # This will run on the 'other' database.
    >>> Author.objects.using('other').all()

Selecting a database for ``save()``
-----------------------------------

Use the ``using`` keyword to ``Model.save()`` to specify to which
database the data should be saved.

For example, to save an object to the ``legacy_users`` database, you'd
use this::

    >>> my_object.save(using='legacy_users')

If you don't specify ``using``, the ``save()`` method will save into
the default database allocated by the routers.

Moving an object from one database to another
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If you've saved an instance to one database, it might be tempting to
use ``save(using=...)`` as a way to migrate the instance to a new
database. However, if you don't take appropriate steps, this could
have some unexpected consequences.

Consider the following example::

    >>> p = Person(name='Fred')
    >>> p.save(using='first')  # (statement 1)
    >>> p.save(using='second') # (statement 2)

In statement 1, a new ``Person`` object is saved to the ``first``
database. At this time, ``p`` doesn't have a primary key, so Django
issues a SQL ``INSERT`` statement. This creates a primary key, and
Django assigns that primary key to ``p``.

When the save occurs in statement 2, ``p`` already has a primary key
value, and Django will attempt to use that primary key on the new
database. If the primary key value isn't in use in the ``second``
database, then you won't have any problems -- the object will be
copied to the new database.

However, if the primary key of ``p`` is already in use on the
``second`` database, the existing object in the ``second`` database
will be overridden when ``p`` is saved.

You can avoid this in two ways. First, you can clear the primary key
of the instance. If an object has no primary key, Django will treat it
as a new object, avoiding any loss of data on the ``second``
database::

    >>> p = Person(name='Fred')
    >>> p.save(using='first')
    >>> p.pk = None # Clear the primary key.
    >>> p.save(using='second') # Write a completely new object.

The second option is to use the ``force_insert`` option to ``save()``
to ensure that Django does a SQL ``INSERT``::

    >>> p = Person(name='Fred')
    >>> p.save(using='first')
    >>> p.save(using='second', force_insert=True)

This will ensure that the person named ``Fred`` will have the same
primary key on both databases. If that primary key is already in use
when you try to save onto the ``second`` database, an error will be
raised.

Selecting a database to delete from
-----------------------------------

By default, a call to delete an existing object will be executed on
the same database that was used to retrieve the object in the first
place::

    >>> u = User.objects.using('legacy_users').get(username='fred')
    >>> u.delete() # will delete from the `legacy_users` database

To specify the database from which a model will be deleted, pass a
``using`` keyword argument to the ``Model.delete()`` method. This
argument works just like the ``using`` keyword argument to ``save()``.

For example, if you're migrating a user from the ``legacy_users``
database to the ``new_users`` database, you might use these commands::

    >>> user_obj.save(using='new_users')
    >>> user_obj.delete(using='legacy_users')

Using managers with multiple databases
--------------------------------------

Use the ``db_manager()`` method on managers to give managers access to
a non-default database.

For example, say you have a custom manager method that touches the
database -- ``User.objects.create_user()``. Because ``create_user()``
is a manager method, not a ``QuerySet`` method, you can't do
``User.objects.using('new_users').create_user()``. (The
``create_user()`` method is only available on ``User.objects``, the
manager, not on ``QuerySet`` objects derived from the manager.) The
solution is to use ``db_manager()``, like this::

    User.objects.db_manager('new_users').create_user(...)

``db_manager()`` returns a copy of the manager bound to the database you specify.

Using ``get_query_set()`` with multiple databases
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If you're overriding ``get_query_set()`` on your manager, be sure to
either call the method on the parent (using ``super()``) or do the
appropriate handling of the ``_db`` attribute on the manager (a string
containing the name of the database to use).

For example, if you want to return a custom ``QuerySet`` class from
the ``get_query_set`` method, you could do this::

    class MyManager(models.Manager):
        def get_query_set(self):
            qs = CustomQuerySet(self.model)
            if self._db is not None:
                qs = qs.using(self._db)
            return qs

Exposing multiple databases in Django's admin interface
=======================================================

Django's admin doesn't have any explicit support for multiple
databases. If you want to provide an admin interface for a model on a
database other than that that specified by your router chain, you'll
need to write custom :class:`~django.contrib.admin.ModelAdmin` classes
that will direct the admin to use a specific database for content.

``ModelAdmin`` objects have five methods that require customization for
multiple-database support::

    class MultiDBModelAdmin(admin.ModelAdmin):
        # A handy constant for the name of the alternate database.
        using = 'other'

        def save_model(self, request, obj, form, change):
            # Tell Django to save objects to the 'other' database.
            obj.save(using=self.using)

        def delete_model(self, request, obj):
            # Tell Django to delete objects from the 'other' database
            obj.delete(using=self.using)

        def queryset(self, request):
            # Tell Django to look for objects on the 'other' database.
            return super(MultiDBModelAdmin, self).queryset(request).using(self.using)

        def formfield_for_foreignkey(self, db_field, request=None, **kwargs):
            # Tell Django to populate ForeignKey widgets using a query
            # on the 'other' database.
            return super(MultiDBModelAdmin, self).formfield_for_foreignkey(db_field, request=request, using=self.using, **kwargs)

        def formfield_for_manytomany(self, db_field, request=None, **kwargs):
            # Tell Django to populate ManyToMany widgets using a query
            # on the 'other' database.
            return super(MultiDBModelAdmin, self).formfield_for_manytomany(db_field, request=request, using=self.using, **kwargs)

The implementation provided here implements a multi-database strategy
where all objects of a given type are stored on a specific database
(e.g., all ``User`` objects are in the ``other`` database). If your
usage of multiple databases is more complex, your ``ModelAdmin`` will
need to reflect that strategy.

Inlines can be handled in a similar fashion. They require three customized methods::

    class MultiDBTabularInline(admin.TabularInline):
        using = 'other'

        def queryset(self, request):
            # Tell Django to look for inline objects on the 'other' database.
            return super(MultiDBTabularInline, self).queryset(request).using(self.using)

        def formfield_for_foreignkey(self, db_field, request=None, **kwargs):
            # Tell Django to populate ForeignKey widgets using a query
            # on the 'other' database.
            return super(MultiDBTabularInline, self).formfield_for_foreignkey(db_field, request=request, using=self.using, **kwargs)

        def formfield_for_manytomany(self, db_field, request=None, **kwargs):
            # Tell Django to populate ManyToMany widgets using a query
            # on the 'other' database.
            return super(MultiDBTabularInline, self).formfield_for_manytomany(db_field, request=request, using=self.using, **kwargs)

Once you've written your model admin definitions, they can be
registered with any ``Admin`` instance::

    from django.contrib import admin

    # Specialize the multi-db admin objects for use with specific models.
    class BookInline(MultiDBTabularInline):
        model = Book

    class PublisherAdmin(MultiDBModelAdmin):
        inlines = [BookInline]

    admin.site.register(Author, MultiDBModelAdmin)
    admin.site.register(Publisher, PublisherAdmin)

    othersite = admin.Site('othersite')
    othersite.register(Publisher, MultiDBModelAdmin)

This example sets up two admin sites. On the first site, the
``Author`` and ``Publisher`` objects are exposed; ``Publisher``
objects have an tabular inline showing books published by that
publisher. The second site exposes just publishers, without the
inlines.

Using raw cursors with multiple databases
=========================================

If you are using more than one database you can use
``django.db.connections`` to obtain the connection (and cursor) for a
specific database. ``django.db.connections`` is a dictionary-like
object that allows you to retrieve a specific connection using its
alias::

    from django.db import connections
    cursor = connections['my_db_alias'].cursor()

Limitations of multiple databases
=================================

.. _no_cross_database_relations:

Cross-database relations
------------------------

Django doesn't currently provide any support for foreign key or
many-to-many relationships spanning multiple databases. If you
have used a router to partition models to different databases,
any foreign key and many-to-many relationships defined by those
models must be internal to a single database.

This is because of referential integrity. In order to maintain a
relationship between two objects, Django needs to know that the
primary key of the related object is valid. If the primary key is
stored on a separate database, it's not possible to easily evaluate
the validity of a primary key.

If you're using Postgres, Oracle, or MySQL with InnoDB, this is
enforced at the database integrity level -- database level key
constraints prevent the creation of relations that can't be validated.

However, if you're using SQLite or MySQL with MyISAM tables, there is
no enforced referential integrity; as a result, you may be able to
'fake' cross database foreign keys. However, this configuration is not
officially supported by Django.
